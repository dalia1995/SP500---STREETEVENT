{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bbc5cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALL Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0da12d",
   "metadata": {},
   "source": [
    "# 2023 CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d2e9da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dali/Downloads/Archive/2023\n",
      "/Users/dali/Downloads/Archive/current\n",
      "done\n",
      "AI from presentations 8791\n",
      "AI from QA 12105\n",
      "AI from both 0\n"
     ]
    }
   ],
   "source": [
    "####EXTRACT AI - EARNING CALLS FROM STREET EVENT\n",
    "\n",
    "# Define the parent folder path\n",
    "parent_folder_path = '/Users/dali/Downloads/Archive'\n",
    "total=0\n",
    "num_pattern_wordsT=0\n",
    "num_pattern_wordsqaT=0\n",
    "# Create an empty list to store the extracted data\n",
    "data_list = []\n",
    "\n",
    "#pattern2 = re.compile(r'AI\\b|artificial intelligence\\b|Artificial Intelligence\\b|\\bai\\b|\\bai-\\b',re.IGNORECASE)\n",
    "pattern2 = re.compile(r'(\\bAI\\b)|(\\bai\\b)',re.IGNORECASE)\n",
    "\n",
    "# Name of folders\n",
    "years = ['2023','current']\n",
    "\n",
    "# Iterate over the subdirectories (years) in the parent folder\n",
    "for year in years:\n",
    "    year_folder_path = parent_folder_path+'/'+year\n",
    "    print(year_folder_path)\n",
    "\n",
    "    # Iterate over the XML files in the year folder\n",
    "    for filename in os.listdir(year_folder_path):\n",
    "        count=0\n",
    "        if filename.endswith('.xml'):\n",
    "            xml_file_path = os.path.join(year_folder_path, filename)\n",
    "            # Read the XML content from the file\n",
    "            xml_tree = etree.parse(xml_file_path)\n",
    "            root = xml_tree.getroot()\n",
    "            body_text = root.findtext('.//Body')\n",
    "\n",
    "            # Extract Event ID\n",
    "            event_id = root.attrib.get('Id', '')\n",
    "            start_date = root.findtext('.//startDate')\n",
    "\n",
    "            cusip = root.findtext('.//CUSIP')\n",
    "            # Extract Event Type Name\n",
    "            event_type_name = root.attrib.get('eventTypeName', '')\n",
    "\n",
    "            ######Company Data########\n",
    "            company_name = root.findtext('.//companyName')\n",
    "            company_ticker = root.findtext('.//companyTicker')\n",
    "            company_id = root.findtext('.//companyId')\n",
    "\n",
    "            \n",
    "            ######Presentation########\n",
    "            body_element = root.find('.//Body')\n",
    "            if body_element is not None and body_element.text:\n",
    "                body_text = body_element.text.strip()\n",
    "\n",
    "                pattern = re.compile(r'(?:Presentation|Transcript)\\s+-{1,}\\s+(.*?)\\s+(?:==|=]{2,}|Questions and Answers|q a|]]>)', re.DOTALL)\n",
    "                # Find the presentation or transcript match\n",
    "                presentation_match = pattern.search(body_text)\n",
    "                # Extract the presentation or transcript text\n",
    "                presentation = presentation_match.group(1).strip() if presentation_match else \"\"\n",
    "                # Count the number of words in the presentation \n",
    "                # Count the number of words related to the pattern\n",
    "                num_pattern_words = len(re.findall(pattern2, presentation))\n",
    "                num_pattern_wordsT +=len(re.findall(pattern2, presentation))\n",
    "                #print(num_pattern_words)\n",
    "            \n",
    "\n",
    "            ######Q&A########\n",
    "            body_elementqa = root.find('.//Body')\n",
    "            if body_elementqa is not None and body_elementqa.text:\n",
    "                body_textqa = body_elementqa.text.strip()\n",
    "\n",
    "                patternqa = re.compile(r'==\\s*(?:Questions\\s+and\\s+Answers|q\\s*[na]\\s*a|qa|qna)(.*)', re.DOTALL)\n",
    "                #print(patternqa)\n",
    "            # Find the presentation or transcript match\n",
    "                qa_match = patternqa.search(body_textqa)\n",
    "                #print(qa_match)\n",
    "                # Extract the presentation or transcript text\n",
    "                qa = qa_match.group(1).strip() if qa_match  else \"\"\n",
    "                num_pattern_wordsqa = len(re.findall(pattern2, qa))\n",
    "                num_pattern_wordsqaT += len(re.findall(pattern2, qa))\n",
    "\n",
    "               # if(qa_match is None):\n",
    "                #    print(\"qa\",filename,len(qa.split()))\n",
    "            \n",
    "            total=num_pattern_wordsqa+num_pattern_words\n",
    "           \n",
    "            #total+=num_pattern_words\n",
    "   \n",
    "            \n",
    "            \n",
    "            \n",
    "            # Check if the presentation contains the word \"AI\"\n",
    "            contains_ai = bool(pattern2.search(presentation)) or bool(pattern2.search(qa))\n",
    "            \n",
    "            match = pattern.search(presentation)\n",
    "            #if match:\n",
    "            #    word = match.group()\n",
    "            #    print(word, filename)\n",
    "                \n",
    "                 # Append the extracted data to the data_list\n",
    "            data_list.append({\n",
    "                \"Event ID\": event_id,\n",
    "                'eventTypeName':event_type_name,\n",
    "                \"Start Date\": start_date,\n",
    "                \"CUSIP\": cusip,\n",
    "                \"Company ID\": company_id,\n",
    "                \"Company Name\": company_name,\n",
    "                \"Company Ticker\": company_ticker,\n",
    "                \"AI_term\": contains_ai,\n",
    "                \"AI_term_P\": total\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "print('done')\n",
    "print('AI from presentations',num_pattern_wordsT)\n",
    "print('AI from QA',num_pattern_wordsqaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "623bfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Start Date' column to datetime format\n",
    "df['Start Date'] = pd.to_datetime(df['Start Date'], format='%d-%b-%y %I:%M%p %Z')\n",
    "\n",
    "# Define the start and end dates in the same time zone as 'Start Date' column\n",
    "start_date = pd.to_datetime('2023-03-15').tz_localize('GMT')\n",
    "end_date = pd.to_datetime('2023-05-25').tz_localize('GMT')\n",
    "\n",
    "# Filter the DataFrame based on conditions\n",
    "filtered_df = df[\n",
    "    (df['eventTypeName'] == 'Earning Conference Call/Presentation') &\n",
    "    (df['Start Date'].between(start_date, end_date))\n",
    "]\n",
    "\n",
    "# Define the output Excel file path\n",
    "output_file_path = '/Users/dali/Documents/task 1/SE_EC_AI_Mar_May2023.csv'\n",
    "\n",
    "# Save the DataFrame to an csv file\n",
    "filtered_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f65bde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data = pd.read_csv(\"/Users/dali/Documents/task 1/sp500_by_sectors.csv\")\n",
    "SE_23_data = pd.read_csv(\"/Users/dali/Documents/task 1/SE_EC_AI_Mar_May2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1b9e22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sp500 earning calls: 490\n"
     ]
    }
   ],
   "source": [
    "# Extract the first 6 digits of CUSIP and ncusip columns\n",
    "SE_23_data['CUSIP_6'] = SE_23_data['CUSIP'].apply(lambda x: str(x)[:6])\n",
    "sp500_data['ncusip_6'] = sp500_data['ncusip'].apply(lambda x: str(x)[:6])\n",
    "\n",
    "\n",
    "# Merge the two datasets based on the first 6 digits of CUSIP and ncusip columns\n",
    "merged_data = pd.merge( sp500_data, SE_23_data, left_on='ncusip_6', right_on='CUSIP_6', how='inner')\n",
    "\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "merged_data.drop(['CUSIP_6', 'ncusip_6','start', 'ending',\n",
    "                  'namedt', 'nameenddt','Unnamed: 0','permno'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Drop duplicate entries based on unique cusips in sp500_data\n",
    "merged_data.drop_duplicates(subset=['CUSIP'], inplace=True)\n",
    "\n",
    "\n",
    "# Save the merged data to a new file\n",
    "merged_data.to_csv('/Users/dali/Documents/task 1/merged_data_SP_EC.csv', index=False)#RETURN ALL SP EARNING CALLS \n",
    "\n",
    "\n",
    "num_rows = merged_data.shape[0]\n",
    "print('total sp500 earning calls:',num_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8804c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector: Communication Services, Percentage of True values: 75.0%\n",
      "Sector: Consumer Discretionary, Percentage of True values: 16.42%\n",
      "Sector: Consumer Staples, Percentage of True values: 3.7%\n",
      "Sector: Financials, Percentage of True values: 13.33%\n",
      "Sector: Health Care, Percentage of True values: 13.33%\n",
      "Sector: Industrials, Percentage of True values: 15.94%\n",
      "Sector: Information Technology, Percentage of True values: 63.64%\n",
      "Sector: Materials, Percentage of True values: 3.23%\n",
      "Sector: Real Estate, Percentage of True values: 16.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/kqdccjfj4dl03z7q6lwkyjt80000gq/T/ipykernel_7200/70446688.py:2: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  sector_percentages = sector_counts.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
      "/var/folders/qw/kqdccjfj4dl03z7q6lwkyjt80000gq/T/ipykernel_7200/70446688.py:8: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for sector, percentage in true_percentages.iteritems():\n"
     ]
    }
   ],
   "source": [
    "sector_counts = merged_data.groupby('Sector_Name')['AI_term'].value_counts()\n",
    "sector_percentages = sector_counts.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "\n",
    "# Access the percentage of True values for each sector\n",
    "true_percentages = sector_percentages.loc[:, True]\n",
    "\n",
    "# Print the sector name and the corresponding percentage of True values\n",
    "for sector, percentage in true_percentages.iteritems():\n",
    "    rounded_percentage = round(percentage, 2)\n",
    "    print(f\"Sector: {sector}, Percentage of True values: {rounded_percentage}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb46f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
